{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "from os.path import join, expanduser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import networkx as nx\n",
    "from article_analysis.parse import get_chunk, get_articles, find_doi_chunk_map, load_ngram_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(the, True), (bottom, False), (is, True), (the, True), (new, False), (top, False), ('s, True), (word, False)]\n"
     ]
    }
   ],
   "source": [
    "not_stop_words = ['top', 'bottom']\n",
    "stop_words = [\"'s\"]\n",
    "\n",
    "for w in not_stop_words:\n",
    "#     nlp.Defaults.stop_words.remove(w)\n",
    "    nlp.vocab[w].is_stop = False\n",
    "\n",
    "for w in stop_words:\n",
    "    nlp.vocab[w].is_stop = True\n",
    "\n",
    "# nlp.Defaults.stop_words -= set(not_stop_words)\n",
    "sentence = nlp(\"the bottom is the new top's word\")\n",
    "print([(s, s.is_stop) for s in sentence])\n",
    "# sentence[1].is_stop, sentence[5].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['The'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = expanduser('~/data/jstor/latest/')\n",
    "output_path = expanduser('~/data/jstor/latest/')\n",
    "prefix = 'ngrams_dict'\n",
    "dois = ['10.2307/3069368', '10.2307/20159507']\n",
    "\n",
    "with open(join(output_path, 'registry_json.txt')) as file:\n",
    "    registry_dict = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_chunk(fpath, prefix, index):\n",
    "#     \"\"\"\n",
    "#     return chunk number index\n",
    "#     \"\"\"\n",
    "#     fname = join(fpath, '{0}_{1}.pgz'.format(prefix, index))\n",
    "#     with gzip.open(fname) as fp:\n",
    "#         item = pickle.load(fp)\n",
    "#         return item\n",
    "#     return None\n",
    "\n",
    "# def get_articles(dois, registry_dict, fpath, prefix):\n",
    "#     \"\"\"\n",
    "#     get articles by dois\n",
    "#     \"\"\"\n",
    "#     doi_chunk_map = find_doi_chunk_map(dois, registry_dict)\n",
    "#     chunks_to_load = list(set(doi_chunk_map.values()))\n",
    "#     chunks_dict = {ii: get_chunk(fpath, prefix, ii) for ii in chunks_to_load}\n",
    "#     doi_ngram_dict = {doi:chunks_dict[doi_chunk_map[doi]][doi] for doi in dois}\n",
    "#     return doi_ngram_dict\n",
    "\n",
    "# def find_doi_chunk_map(dois, registry_dict):\n",
    "#     return {k : [kk for kk, val in registry_dict.items() if k in val][0] for k in dois}\n",
    "\n",
    "# def load_ngram_dist(fpath, order, thr=2):\n",
    "#     fname = join(fpath, 'corpus_ngram_dist_n_{0}_thr_{1}.pgz'.format(order, thr))\n",
    "#     with gzip.open(fname) as fp:\n",
    "#         distr_dict = pickle.load(fp)\n",
    "#     if order == 1:\n",
    "#         distr_dict = {k[0]: v for k, v in distr_dict.items()}\n",
    "#     return distr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get articles\n",
    "dch_dict = get_articles(dois, registry_dict, input_path, prefix)\n",
    "\n",
    "ngram_order = 2\n",
    "# get ngrams\n",
    "distr_dict = load_ngram_dist(input_path, ngram_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('c', 'academy', 'management'): [0],\n",
       " ('academy', 'management', 'journal'): [0,\n",
       "  326,\n",
       "  349,\n",
       "  378,\n",
       "  418,\n",
       "  465,\n",
       "  473,\n",
       "  488,\n",
       "  491]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# three grams\n",
    "{k : v for k, v in dch_dict[dois[0]][3].items() if k in list(dch_dict[dois[0]][3].keys())[:2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = sorted(distr_dict.keys())\n",
    "# vals = np.array([distr_dict[k] for k in keys])\n",
    "# df = pd.DataFrame(vals, keys, columns=['f', 'f-', 'f+', 'n']).sort_values('n')\n",
    "# df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2669 (2669, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>n_article</th>\n",
       "      <th>n_corpus</th>\n",
       "      <th>inv_n_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(finkelstein, hambrick)</th>\n",
       "      <td>113.680340</td>\n",
       "      <td>13.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>0.001792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(management, team's)</th>\n",
       "      <td>773.580850</td>\n",
       "      <td>13.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(expansiveness, firm's)</th>\n",
       "      <td>4879.509979</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(demographic, effect)</th>\n",
       "      <td>481.530590</td>\n",
       "      <td>15.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.006579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(tmt, characteristic)</th>\n",
       "      <td>1045.609281</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(firm's, global)</th>\n",
       "      <td>2614.023203</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(firm, tenure)</th>\n",
       "      <td>523.974226</td>\n",
       "      <td>16.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.006711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(relationship, top)</th>\n",
       "      <td>772.991680</td>\n",
       "      <td>16.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.009901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(tmt, demographic)</th>\n",
       "      <td>3318.066786</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(educational, heterogeneity)</th>\n",
       "      <td>3606.594332</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(management, journal)</th>\n",
       "      <td>3.043670</td>\n",
       "      <td>18.0</td>\n",
       "      <td>28857.0</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(functional, heterogeneity)</th>\n",
       "      <td>1084.335551</td>\n",
       "      <td>18.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.012346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(environmental, uncertainty)</th>\n",
       "      <td>57.373858</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>0.000560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(tenure, heterogeneity)</th>\n",
       "      <td>1297.084931</td>\n",
       "      <td>21.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.012658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(management, team)</th>\n",
       "      <td>37.674226</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3497.0</td>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(upper, echelon)</th>\n",
       "      <td>247.179680</td>\n",
       "      <td>27.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>0.001876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(top, team)</th>\n",
       "      <td>294.735502</td>\n",
       "      <td>27.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>0.002237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(top, management)</th>\n",
       "      <td>32.404468</td>\n",
       "      <td>43.0</td>\n",
       "      <td>6475.0</td>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(strategic, posture)</th>\n",
       "      <td>1262.267060</td>\n",
       "      <td>67.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>0.003861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(global, strategic)</th>\n",
       "      <td>1543.286877</td>\n",
       "      <td>68.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.004651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tf_idf  n_article  n_corpus  inv_n_corpus\n",
       "(finkelstein, hambrick)        113.680340       13.0     558.0      0.001792\n",
       "(management, team's)           773.580850       13.0      82.0      0.012195\n",
       "(expansiveness, firm's)       4879.509979       13.0      13.0      0.076923\n",
       "(demographic, effect)          481.530590       15.0     152.0      0.006579\n",
       "(tmt, characteristic)         1045.609281       15.0      70.0      0.014286\n",
       "(firm's, global)              2614.023203       15.0      28.0      0.035714\n",
       "(firm, tenure)                 523.974226       16.0     149.0      0.006711\n",
       "(relationship, top)            772.991680       16.0     101.0      0.009901\n",
       "(tmt, demographic)            3318.066786       17.0      25.0      0.040000\n",
       "(educational, heterogeneity)  3606.594332       17.0      23.0      0.043478\n",
       "(management, journal)            3.043670       18.0   28857.0      0.000035\n",
       "(functional, heterogeneity)   1084.335551       18.0      81.0      0.012346\n",
       "(environmental, uncertainty)    57.373858       21.0    1786.0      0.000560\n",
       "(tenure, heterogeneity)       1297.084931       21.0      79.0      0.012658\n",
       "(management, team)              37.674226       27.0    3497.0      0.000286\n",
       "(upper, echelon)               247.179680       27.0     533.0      0.001876\n",
       "(top, team)                    294.735502       27.0     447.0      0.002237\n",
       "(top, management)               32.404468       43.0    6475.0      0.000154\n",
       "(strategic, posture)          1262.267060       67.0     259.0      0.003861\n",
       "(global, strategic)           1543.286877       68.0     215.0      0.004651"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a single article\n",
    "article = dch_dict[dois[0]]\n",
    "ngram_positions_list = article[ngram_order]\n",
    "ngram_counts = {k: len(v) for k, v in ngram_positions_list.items()}\n",
    "ngram_number = sum(ngram_counts.values())\n",
    "ngram_freqs = {k: v/ngram_number for k, v in ngram_counts.items() if k in distr_dict.keys()}\n",
    "len(ngram_freqs)\n",
    "\n",
    "ngram_freqs_outstanding = {k: v/distr_dict[k][0] for k, v in ngram_freqs.items()} \n",
    "len(ngram_counts), len(ngram_freqs), len(ngram_freqs_outstanding)\n",
    "\n",
    "keys = sorted(ngram_freqs_outstanding.keys())\n",
    "vals = np.array([(ngram_freqs_outstanding[k], ngram_counts[k], distr_dict[k][-1], 1./distr_dict[k][-1]) \n",
    "                 for k in keys])\n",
    "print(len(keys), vals.shape)\n",
    "df = pd.DataFrame(vals, keys, columns=['tf_idf', 'n_article', \n",
    "                                       'n_corpus', 'inv_n_corpus']).sort_values(['n_article', 'inv_n_corpus'])\n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_order = 1\n",
    "ngram_positions_list = article[ngram_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ixs = ngram_positions_list['hypothesis'] + ngram_positions_list['hypothesis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = expanduser('~/data/jstor/latest/corpus_clean_dict.pgz')\n",
    "with gzip.open(fname) as fp:\n",
    "    articles_ds = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "carticle = articles_ds[dois[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a positive relationship\n",
      "a positive relationship\n",
      "a positive relationship\n",
      "a positive relationship\n",
      "the relationship\n",
      "the linear relationships\n",
      "U - relationship\n",
      "U - relationship\n",
      "U - relationship\n",
      "U - relationship\n",
      "the relationship\n",
      "the previously proposed linear relationships\n",
      "the previously proposed linear relationships\n",
      "the previously proposed linear relationships\n",
      "the previously proposed linear relationships\n",
      "the main effect relationships\n",
      "the relationship\n",
      "the relationship\n",
      "such relationships\n",
      "the moderated relationships\n",
      "a negative linear relationship\n",
      "the relationship\n",
      "such relationships\n",
      "an inverted - or curvilinear relationship\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "inds = [range(i-1, i+2) for i in ixs]\n",
    "overlap_indices = sorted(list(set([x for sublist in inds for x in sublist])))\n",
    "\n",
    "for j in overlap_indices:\n",
    "    phrase = ' '.join(carticle[j])\n",
    "    doc = nlp(phrase)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        supp_chunk = [c for c in chunk if not c.is_stop and not c.text.lower() in nlp.Defaults.stop_words]\n",
    "        if supp_chunk and chunk.root.pos_ == 'NOUN':\n",
    "            edge_slist = [[(c.lemma_, d.lemma_) for d in c.children if d in supp_chunk] for c in supp_chunk]\n",
    "            edge_list = [e for sublist in edge_slist for e in sublist]\n",
    "            g = nx.Graph()\n",
    "            edge_list += [('#', chunk.root.lemma_)]\n",
    "            g.add_edges_from(edge_list)\n",
    "            supp_chunk2 = [c.lemma_ for c in supp_chunk]\n",
    "            chunks.append((chunk.root.lemma_, tuple(supp_chunk2), g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_dict = {}\n",
    "for r, np, tr in chunks:\n",
    "    if r in chunks_dict:\n",
    "        if np in chunks_dict[r].keys():\n",
    "             chunks_dict[r][np] += 1\n",
    "        else:\n",
    "            chunks_dict[r][np] = 1\n",
    "    else:\n",
    "        chunks_dict[r] = {np: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'breadth': {('breadth',): 2},\n",
       " 'diversity': {('diversity',): 3},\n",
       " 'posture': {('global', 'strategic', 'posture'): 8,\n",
       "  ('firm', 'global', 'strategic', 'posture'): 12,\n",
       "  ('expansive', 'global', 'strategic', 'posture'): 1},\n",
       " 'relationship': {('positive', 'relationship'): 4,\n",
       "  ('relationship',): 7,\n",
       "  ('linear', 'relationship'): 1,\n",
       "  ('u', '-', 'relationship'): 4,\n",
       "  ('previously', 'propose', 'linear', 'relationship'): 4,\n",
       "  ('main', 'effect', 'relationship'): 1,\n",
       "  ('moderate', 'relationship'): 1,\n",
       "  ('negative', 'linear', 'relationship'): 1,\n",
       "  ('invert', '-', 'curvilinear', 'relationship'): 1},\n",
       " 'experience': {('management',\n",
       "   'team',\n",
       "   'international',\n",
       "   'work',\n",
       "   'experience'): 3,\n",
       "  ('international', 'work', 'experience'): 1,\n",
       "  ('tmt', 'international', 'experience'): 1,\n",
       "  ('dramatically', 'different', 'functional', 'experience'): 1}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: chunks_dict[k] for k in list(chunks_dict.keys())[:5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = {k: sum(chunks_dict[k].values()) for k in list(chunks_dict.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['heterogeneity',\n",
       " 'relationship',\n",
       " 'posture',\n",
       " 'hypothesis',\n",
       " 'uncertainty',\n",
       " 'model',\n",
       " 'expansiveness',\n",
       " 'level',\n",
       " 'set',\n",
       " 'characteristic',\n",
       " 'effect',\n",
       " 'team',\n",
       " 'variable',\n",
       " 'result',\n",
       " 'experience']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_keys = sorted(total_counts, key=total_counts.get, reverse=True)\n",
    "root_candidates = [k for k in pop_keys if total_counts[k] > 5 and len(k) > 2]\n",
    "root_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "chunks_dict2 = {k: v for k, v in chunks_dict.items() if len(k) > 2}\n",
    "print(len(chunks_dict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "chunks_dict3 = {k: {q: w for q, w in v.items() if w > 1 and len(q) > 2} for k, v in chunks_dict2.items() if len(k) > 2}\n",
    "chunks_dict4 = {k: v for k, v in chunks_dict3.items() if v}\n",
    "print(len(chunks_dict4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'posture': {('global', 'strategic', 'posture'): 8,\n",
       "  ('firm', \"'s\", 'global', 'strategic', 'posture'): 12},\n",
       " 'relationship': {('U', '-', 'relationship'): 4},\n",
       " 'experience': {('top',\n",
       "   'management',\n",
       "   'team',\n",
       "   \"'s\",\n",
       "   'international',\n",
       "   'work',\n",
       "   'experience'): 3},\n",
       " 'heterogeneity': {('top',\n",
       "   'management',\n",
       "   'team',\n",
       "   \"'s\",\n",
       "   'educational',\n",
       "   'heterogeneity'): 3,\n",
       "  ('top', 'management', 'team', \"'s\", 'functional', 'heterogeneity'): 3,\n",
       "  ('top', 'management', 'team', \"'s\", 'firm', 'tenure', 'heterogeneity'): 3},\n",
       " 'studies': {('upper', 'echelons', 'studies'): 2},\n",
       " 'teams': {('top', 'management', 'teams'): 2},\n",
       " 'relationships': {('previously', 'proposed', 'linear', 'relationships'): 4}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_dict4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('07', 't'), ('Environmental', 'uncertainty'),\n",
       "       ('TMT', 'characteristics'), ('U', '-', 'relationship'),\n",
       "       ('educational', 'heterogeneity'),\n",
       "       ('firm', \"'s\", 'global', 'strategic', 'posture'),\n",
       "       ('functional', 'heterogeneity'),\n",
       "       ('global', 'strategic', 'posture'), ('positive', 'relationship'),\n",
       "       ('previously', 'proposed', 'linear', 'relationships'),\n",
       "       ('top', 'management', 'team', \"'s\", 'educational', 'heterogeneity'),\n",
       "       ('top', 'management', 'team', \"'s\", 'firm', 'tenure', 'heterogeneity'),\n",
       "       ('top', 'management', 'team', \"'s\", 'functional', 'heterogeneity'),\n",
       "       ('top', 'management', 'team', \"'s\", 'international', 'work', 'experience'),\n",
       "       ('top', 'team')], dtype=object)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unis[(cnts > 2) & np.array([len(x) > 1 for x in unis]) & chunk.root.pos_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk.root.pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words: 305\n",
      "First ten stop words: ['himself', 'each', 'if', 'will', 'no', 'others', 'sixty', 'he', 'did', 'we', 'could', 'the', 'using', 'say', 'whither', 'nowhere', 'ours', 'once', 'third', 'thereby', 'least', 'part', 'further', 'seem', 'whose', 'another', 'some', 'one', 'back', 'by', 'forty', 'has', 'last', 'upon', 'except', 'various', 'too', 'though', 'often', 'yourself', 'both', 'any', 'eight', 'during', 'former', 'next', 'had', 'almost', 'than', 'either', 'noone', 'from', 'make', 'thru', 'else', 'of', 'onto', 'see', 'hers', 'they', 'may', 'been', 'per', 'mostly', 'here', 'sometime', 'you', 'might', 'sometimes', 'hundred', 'wherever', 'into', 'off', 'yet', 'seemed', 'yourselves', 'these', 'otherwise', 'via', 'anyone', 'although', 'whoever', \"'s'\", 'thereafter', 'across', 'around', 'several', 'show', 'whereupon', 'everything', 'myself', 'do', 'along', 'then', 'everyone', 'empty', 'but', 'against', 'side', 'whereas']\n"
     ]
    }
   ],
   "source": [
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS | {\"'s'\"}\n",
    "spacy_stopwords = spacy_stopwords - {'top'}\n",
    "print('Number of stop words: %d' % len(spacy_stopwords))\n",
    "print('First ten stop words: %s' % list(spacy_stopwords)[:100])\n",
    "# stop_words.append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nevertheless nevertheless ADV RB advmod Xxxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "we -PRON- PRON PRP nsubj xx True True\n",
      "found find VERB VBD ROOT xxxx True False\n",
      "no no DET DT det xx True True\n",
      "support support NOUN NN dobj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "the the DET DT det xxx True True\n",
      "curvilinear curvilinear NOUN NN compound xxxx True False\n",
      "predictions prediction NOUN NNS pobj xxxx True False\n",
      "the the DET DT det xxx True True\n",
      "second second ADJ JJ amod xxxx True False\n",
      "set set NOUN NN oprd xxx True False\n",
      "of of ADP IN prep xx True True\n",
      "hypotheses hypothesis NOUN NNS pobj xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "and and CCONJ CC cc xxx True True\n",
      "our -PRON- ADJ PRP$ poss xxx True True\n",
      "results result NOUN NNS nsubj xxxx True False\n",
      "suggest suggest VERB VBP conj xxxx True False\n",
      "instead instead ADV RB advmod xxxx True False\n",
      "a a DET DT det x True True\n",
      "refinement refinement NOUN NN dobj xxxx True False\n",
      "to to ADP IN prep xx True True\n",
      "such such ADJ JJ amod xxxx True True\n",
      "theorizing theorize VERB VBG pobj xxxx True False\n",
      ". . PUNCT . punct . False False\n"
     ]
    }
   ],
   "source": [
    "# doc = nlp(phrase)\n",
    "# for token in doc:\n",
    "#     print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "#           token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arguments | arguments nsubj hold\n",
      "the nonmonotonic effects | effects pobj about\n",
      "heterogeneity | heterogeneity pobj of\n",
      "some demographic characteristics | characteristics pobj for\n",
      "one | one nsubj take\n",
      "account | account pobj into\n",
      "the level | level dobj take\n",
      "uncertainty | uncertainty pobj of\n",
      "a top team | team dobj facing\n"
     ]
    }
   ],
   "source": [
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, '|', chunk.root.text, chunk.root.dep_,\n",
    "          chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "inds = [range(i-1, i+2) for i in ixs]\n",
    "overlap_indices = sorted(list(set([x for sublist in inds for x in sublist])))\n",
    "\n",
    "for j in overlap_indices:\n",
    "    phrase = ' '.join(carticle[j])\n",
    "    doc = nlp(phrase)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        supp_chunk = [c for c in chunk if not c.is_stop]\n",
    "        if supp_chunk and chunk.root.pos_ == 'NOUN':\n",
    "            edge_slist = [[(c,d) for d in c.children if d in supp_chunk] for c in supp_chunk]\n",
    "            edge_list = [e for sublist in edge_slist for e in sublist]\n",
    "            g = nx.Graph()\n",
    "            edge_list += [('#', chunk.root)]\n",
    "            g.add_edges_from(edge_list)\n",
    "            supp_chunk2 = [c.text for c in supp_chunk]\n",
    "            chunks.append((chunk.root, tuple(supp_chunk2), g))\n",
    "#         print(chunk.text, '|', chunk.root.text, chunk.root.dep_,\n",
    "#               chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = chunk[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amod'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
