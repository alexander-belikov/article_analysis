{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from os.path import expanduser, join, isfile\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from os import listdir\n",
    "import gzip\n",
    "import pickle\n",
    "import article_analysis.parse as aap\n",
    "from collections import Counter\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport article_analysis.parse\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "fpath = expanduser('~/data/jstor/ngrams_new')\n",
    "destpath = fpath\n",
    "suffix = 'pgz'\n",
    "prefix = 'lemma_ngrams_corpus'\n",
    "indx = aap.get_indices(fpath, prefix, suffix)\n",
    "print(indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 chunks procs\n",
      "2 chunks procs\n",
      "3 chunks procs\n",
      "4 chunks procs\n",
      "5 chunks procs\n",
      "6 chunks procs\n"
     ]
    }
   ],
   "source": [
    "super_ngram = {i: Counter() for i in range(2, 6)}\n",
    "for ii in indx[:]:\n",
    "    chunk = aap.get_chunk(fpath, 'lemma_ngrams_corpus', ii)\n",
    "    ckeys = sorted(chunk.keys())\n",
    "    for k in ckeys:\n",
    "        for o in range(2, 6):\n",
    "            super_ngram[o] += chunk[k][o]\n",
    "    print('{0} chunks procs'.format(ii))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457649 791965\n",
      "617535 713625\n",
      "600316 644267\n",
      "556496 582502\n"
     ]
    }
   ],
   "source": [
    "for o in range(2, 6):\n",
    "    s = sum([x for x in super_ngram[o].values()])\n",
    "    print(len(super_ngram[o]), s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(join(destpath, 'lemma_ngrams_corpus_total.pgz'.format(ii)), 'wb') as fp:\n",
    "        pickle.dump(super_ngram, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
