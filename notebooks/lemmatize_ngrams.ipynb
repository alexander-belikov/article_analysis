{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lucem_illud #pip install -U git+git://github.com/Computational-Content-Analysis-2018/lucem_illud.git\n",
    "import gensim\n",
    "import requests\n",
    "import nltk #For stop words and stemmers\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import sklearn.metrics.pairwise\n",
    "import sklearn.manifold\n",
    "import sklearn.decomposition\n",
    "from os.path import expanduser, join, isfile\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from os import listdir\n",
    "import re\n",
    "import gzip\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "import os #For looking through files\n",
    "import os.path #For managing file paths\n",
    "\n",
    "import article_analysis.parse as aap\n",
    "import enchant\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport article_analysis.parse\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(fpath, prefix, suffix):\n",
    "    suffix_len = len(suffix)\n",
    "    prefix_len = len(prefix)\n",
    "    files = [f for f in listdir(fpath) if isfile(join(fpath, f)) and\n",
    "             (f[-suffix_len:] == suffix and f[:prefix_len] == prefix)]\n",
    "    ints = [int(f.split('_')[-1].split('.')[0]) for f in files]\n",
    "    return sorted(ints)\n",
    "\n",
    "def get_chunk(fpath, index):\n",
    "    fname = join(fpath, 'ngrams_corpus_{0}.pgz'.format(index))\n",
    "    with gzip.open(fname) as fp:\n",
    "        item = pickle.load(fp)\n",
    "        return item\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = expanduser('~/data/jstor/ngrams_new')\n",
    "destpath = fpath\n",
    "suffix = 'pgz'\n",
    "prefix = 'ngrams_corpus'\n",
    "get_indices(fpath, prefix, suffix)\n",
    "chunk = get_chunk(fpath, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmtzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 chunks procs\n",
      "2 chunks procs\n",
      "3 chunks procs\n",
      "4 chunks procs\n",
      "5 chunks procs\n",
      "6 chunks procs\n",
      "7 chunks procs\n",
      "8 chunks procs\n",
      "9 chunks procs\n",
      "10 chunks procs\n",
      "11 chunks procs\n",
      "12 chunks procs\n",
      "13 chunks procs\n",
      "14 chunks procs\n",
      "15 chunks procs\n",
      "16 chunks procs\n",
      "17 chunks procs\n",
      "18 chunks procs\n",
      "19 chunks procs\n",
      "20 chunks procs\n",
      "21 chunks procs\n",
      "22 chunks procs\n",
      "23 chunks procs\n",
      "24 chunks procs\n",
      "25 chunks procs\n",
      "26 chunks procs\n",
      "27 chunks procs\n",
      "28 chunks procs\n",
      "29 chunks procs\n"
     ]
    }
   ],
   "source": [
    "indx = get_indices(fpath, prefix, suffix)\n",
    "\n",
    "for ii in indx[:]:\n",
    "    chunk = get_chunk(fpath, ii)\n",
    "    nc = aap.transform_chunk(chunk, lmtzr)\n",
    "    with gzip.open(join(destpath, 'lemma_ngrams_corpus_{0}.pgz'.format(ii)), 'wb') as fp:\n",
    "            pickle.dump(nc, fp)\n",
    "    print('{0} chunks procs'.format(ii))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
